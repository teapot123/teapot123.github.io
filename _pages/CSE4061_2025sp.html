---
layout: archive	
title: " CSE 4061: Text Mining (2025 Spring)"
permalink: /CSE4061_2025sp/
author_profile: true	  
---


<h2 id="course-overview">Course Overview</h2>
<p>This is an advanced research-oriented course that teaches fundamental techniques of text mining and natural language processing. It is a rapidly evolving field at the intersection of natural language processing and machine learning. Students will gain both in-depth knowledge of fundamental concepts and hands-on experience in practical applications.<br>Pre-requisites: Students are expected to understand concepts in machine learning (CSE 417T/517A)</p>


<h2 id="ta">Teaching Assistants</h2>
<p><strong>Langlin Huang</strong> (h.langlin@wustl.edu)<br>
<strong>Xinhang Yuan</strong> (xinhang.y@wustl.edu)</p>

<h2 id="course-grading">Course Grading</h2>
<ul>
<li>10% Class Participation<ul>
<li>Regular class participation and discussion (10%)</li>
</ul>
</li>
<li>60% Programming Assignments
<ul>
<li>4 programming assignments, each account for 15%</li>
<li>5 days of grace period in total for all assignments</li>
<li>After grace period is used up, late assignments receive 0 score</li>
</ul>
</li>
<li>30% Final Project (Group-Based, 2-3 people)
<ul>
<li>5% Project Proposal (Due: 2/4, 11:59PM)</li>
<li>5% Mid-term Report (Due: 3/3, 11:59PM)</li>
<li>10% Final Course Presentation (Due: 4/14, 11:59PM)</li>
<li>We will use two lectures for project presentation: 4/15, 4/17
</li>
<li>10% Final Project Report (Due: 5/2, 11:59PM)</li>
</ul>
</li>
</ul>

<h2 id="final-project-2-3-students-per-group-">Final Project (2-3 students per group)</h2>
<p>Project Requirement: Demonstrate that you are able to apply the knowledge and techniques learned from this course. The project requires more complex implementation than the programming assignments. Topics include but not limited to: </p>
<ol>
<li>Investigate word embeddings and sentence embeddings for text classification problems.</li>
<li>Train a medium-sized language model (e.g., BERT, GPT-2) for tasks that you are interested in.</li>
<ul><li><a href="https://huggingface.co/models">https://huggingface.co/models</a></li></ul>
<li>Do inference on large language models (white box models such as LLaMA models, or black box models such as GPT-4, CLAUDE, etc.) to solve some type of complex problems, and analyze their limitations.</li>
<ul><li><a href="https://platform.openai.com/docs/introduction">https://platform.openai.com/docs/introduction</a></li>
<li><a href="https://docs.anthropic.com/claude/reference/getting-started-with-the-api">https://docs.anthropic.com/claude/reference/getting-started-with-the-api</a></li>
</ul>
<li>Create benchmark for new and challenging tasks and test it with SoTA models.</li>
<ul></ul>
</ol>

<p>Project Presentation Date: 4/15 and 4/17, 2025. You will need to signup for a time slot near the end of the semester. Presentation length will be 10-15 minutes depending on the number of groups.
</p>

<h2 id="office-hour">Office Hour</h2>
<p>Instructor Office Hour: Thursday After Class - 5pm at McKelvey Hall 2010E</p>
<p>TA Office Hour: Tuesday 10-11am at McKelvey Hall 2040 (Langlin Huang)</p>
<p>TA Office Hour: Friday 10-11am at McKelvey Hall 2040 (Xinhang Yuan)</p>

<h2 id="course-policies">Course Policies</h2>
<ul>
<li>LLM Usage Policy:
<ul>
<li>It is fine to collaborate with LLMs for coding assignments and refining your reports. However, directly using LLM generated outputs without manual check results in 0 score of the assignment.</li>
</ul>
</li>
<li>Extra Credit:
<ul>
<li>Students who first correctly answers technical questions (excluding assignment questions) raised by other students on Piazza will get 1 bonus point each time, up to 3 points in total.</li>
</ul>
</li>
</ul>


<h2 id="syllabus-the-dates-of-the-courses-are-tentative-due-to-guest-lectures-">Syllabus (The content of each class is tentative.)</h2>

<table>
    <tr>
        <td><strong>Week</strong></td>
        <td><strong>Date</strong></td>
        <td><strong>Topic</strong></td>
        <td><strong>Assignment</strong></td>
    </tr>
    <tr>
        <td rowspan="2">Week 1</td>
        <td>01/14</td>
        <td>Course Overview</td>
        <td></td>
    </tr>
    <tr>
        <td>01/16</td>
        <td>N-gram Models</td>
        <td></td>
    </tr>
    <tr>
        <td rowspan="2">Week 2</td>
        <td>01/21</td>
        <td>Bag of Words, TF-IDF</td>
        <td></td>
    </tr>
    <tr>
        <td>01/23</td>
        <td>Topic Modeling</td>
        <td></td>
    </tr>
    <tr>
        <td rowspan="2">Week 3</td>
        <td>01/28</td>
        <td>Neural Word Embeddings</td>
        <td></td>
    </tr>
    <tr>
        <td>01/30</td>
        <td>Neural Word Embeddings and Neural Topic Modeling</td>
        <td>HW1 Out</td>
    </tr>
    <tr>
        <td rowspan="2">Week 4</td>
        <td>02/04</td>
        <td>Neural Sequence Modeling (RNN, LSTM)</td>
        <td></td>
    </tr>
    <tr>
        <td>02/06</td>
        <td>Neural Sequence Modeling and Self Attention</td>
        <td></td>
    </tr>
    <tr>
        <td rowspan="2">Week 5</td>
        <td>02/11</td>
        <td>Transformer architectures</td>
        <td>HW1 Due</td>
    </tr>
    <tr>
        <td>02/13</td>
        <td>LLM Pre-training</td>
        <td></td>
    </tr>
    <tr>
        <td rowspan="2">Week 6</td>
        <td>02/18</td>
        <td>Text Mining Applications: Sentiment Analysis</td>
        <td>HW2 Out</td>
    </tr>
    <tr>
        <td>02/20</td>
        <td>Text Mining Applications: Information Extraction</td>
        <td></td>
    </tr>
    <tr>
        <td rowspan="2">Week 7</td>
        <td>02/25</td>
        <td>Large Language Models: Pre-training and Scaling</td>
        <td></td>
    </tr>
    <tr>
        <td>02/27</td>
        <td>Instruction Tuning</td>
        <td>HW2 Due</td>
    </tr>
    <tr>
        <td rowspan="2">Week 8</td>
        <td>03/04</td>
        <td>Advanced LLM reasoning (I)</td>
        <td>HW3 Out</td>
    </tr>
    <tr>
        <td>03/06</td>
        <td>Advanced LLM reasoning (II)</td>
        <td></td>
    </tr>
    <tr>
        <td colspan="4" align="center"><strong>Spring Break</strong></td>
    </tr>
    <tr>
        <td rowspan="2">Week 10</td>
        <td>03/18</td>
        <td>Reinforcement Learning with Human Feedback</td>
        <td>HW3 Due</td>
    </tr>
    <tr>
        <td>03/20</td>
        <td>Language Model Factuality</td>
        <td>HW4 Out</td>
    </tr>
    <tr>
        <td rowspan="2">Week 11</td>
        <td>03/25</td>
        <td>LLM Training Efficiency</td>
        <td></td>
    </tr>
    <tr>
        <td>03/27</td>
        <td>LLM Inference Efficiency</td>
        <td></td>
    </tr>
    <tr>
        <td rowspan="2">Week 12</td>
        <td>04/01</td>
        <td>LLM Applications: Retrieval-Augmented Generation</td>
        <td>HW4 Due</td>
    </tr>
    <tr>
        <td>04/03</td>
        <td>LLM Applications: Agents</td>
        <td></td>
    </tr>
    <tr>
        <td rowspan="2">Week 13</td>
        <td>04/08</td>
        <td>LLM Multi-modality</td>
        <td></td>
    </tr>
    <tr>
        <td>04/10</td>
        <td>Future Directions</td>
        <td></td>
    </tr>
    <tr>
        <td rowspan="2">Week 14</td>
        <td>04/15</td>
        <td>Final Project Presentations</td>
        <td></td>
    </tr>
    <tr>
        <td>04/17</td>
        <td colspan="2">Final Project Presentations</td>
        <td></td>
    </tr>
</table>
